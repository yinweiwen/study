#### AI技术逻辑研发建议书



#### 4.技术路线

(重点技术和实现路径)

概述：使用开源的大语言模型(LLM)，并将我司相关业务数据库、数据文档喂给模型，然后通过API和前端应用，建立智能知识库，实现智能问答系统。

+ 数据收集

  首先是收集企业内部私有知识库数据，这包括内部文档、邮件、报告、会议记录等。可以与禅道、OA、邮箱、wiki等系统对接，以及飞尚公司主页中爬取相关产品信息，以及可以从以太平台获取具体设备的详细内容。在本系统中主要负责收集QA常见问题、解决方案、操作指南等运维知识。

  注意这些信息中可能存在一些敏感涉密的信息，需要进行过滤和筛选。目前已知的比如涉密方案、项目合同报价、平台账户密码、以及其他用户隐私。在开发这部分数据收集和爬虫程序时，需要考虑和审核这部分数据，进行脱敏处理。

  数据需要进行一次性收集和定时增量收集，以保持知识库的及时性和完整性。

+ 载入模型

  利用开源的大语言模型（LLM）,主要是基于文本生成的生成式AI（NLP），如GLM或BERT，将收集到的企业内部数据加载到模型中进行预训练。

  在载入模型时，需要考虑数据的格式和预处理，确保模型能够正确地理解和学习数据的内容和语境。

+ 智能应用

  开发智能问答应用，通过模型实现对用户提出的问题进行理解和回答。用户可以通过前端应用或API接口与智能问答系统进行交互，提出问题并获取回答。
  前端应用主要是Web界面（集成在PEP项企管理系统或POMS运维中台中）以及与企业微信对接，实现聊天工具AI助手。

+ 持续学习

  不间断收集企业内部增量信息，通过定期的模型重新训练、增量训练等方式，优化模型。提高智能问答系统的准确性和及时性。

  同时，收集用户数据和反馈，提供模型参数修正的依据，以达到持续优化模型的目的。

  

开源模型选择

| 模型       | 训练数据                             | 训练数据量     | 模型参数量                       | 词表大小 |
| ---------- | ------------------------------------ | -------------- | -------------------------------- | -------- |
| LLaMA      | 以英语为主的拉丁语系，不包含中日韩文 | 1T/1.4T tokens | 7B、13B、33B、65B                | 32000    |
| ChatGLM-6B | 中英双语，中英文比例为1:1            | 1T tokens      | 6B                               | 130528   |
| Bloom      | 46种自然语言和13种编程语言，包含中文 | 350B tokens    | 560M、1.1B、1.7B、3B、7.1B、176B | 250880   |

> 截至当前ChatGLM已经出到ChatGLM3-6B，并已开源到`HuggingFace`。
>
> 总结的优秀GenAI Model：
>
> OpenAI API - OpenAI的API提供了对GPT-3和GPT-4模型的访问，这些模型执行各种自然语言任务，并且还有Codex，它可以将自然语言转换为代码。
> Gopher - 由DeepMind开发的Gopher是一个拥有2800亿参数的语言模型。
> OPT - Facebook的Open Pretrained Transformers（OPT）是一套仅解码器的预训练transformers套件。它是通过Alpa托管的OPT-175B文本生成模型。
> Bloom - Hugging Face的BLOOM是一个类似于GPT-3的模型，它经过了在46种不同语言和13种编程语言上的训练。#opensource
> LLaMA - Meta开发的基础性的、拥有650亿参数的大型语言模型。#opensource
> Llama 2 - Meta的开源大型语言模型的下一代。#opensource
> Claude 2 - 与Claude交流，Claude是Anthropic的一个AI助手。
> Vicuna-13B - 通过对从ShareGPT收集的用户共享对话进行微调，Meta开发的开源聊天机器人。
> Mixtral 8x7B - 一种高质量的稀疏专家混合模型，具有开放的权重。



在智能系统搭建中，选择开源产品[Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat)，它负责连接应用与模型，支持完全独立的本地化部署，能够更好的保护数据隐私，并支持多种格式的知识文件上传。工作原理参考`LangChain-Chatchat`官网流程框图，包括加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 `top k`个 -> 匹配出的文本作为上下文和问题一起添加到 `prompt`中 -> 提交给 `LLM`生成回答。

我们基于`LangChain-Chatchat`实现自动化知识库更新和智能问答助手，主要的开发工作包含：

+ 基于微信API实现企业微信聊天助手
+ 自动加载和更新企业内部知识内容（主要运维相关）
+ 基于大模型参数的调整达到较为理想的效果。

![实现原理图](langchain+chatglm.png)



#### 5.创新点

创新点： 



1. 结合我司业务场景，实现私有企业知识库，可以根据垂直领域，提供全面、精确和实用的知识服务。
2. 构建智能问答系统，使用户能够更便捷地获取所需信息，提高工作效率。

难点：

1. 数据收集过程中数据脱敏，保证数据的合规性。同时应该清洗掉明显的错误内容。
2. 数据模型的调优，需要有一定的机器学习理论知识和技术支持。
3. 需要结合硬件算力能力，提供合适的模型大小。较小参数的模型回答准确性需要评估验证可接受的准确率。
4. AI可能生成虚构的、明显错误的信息和场景，有些错误可能导致较大的认知错误。故无法从AI分析结果执行明确的规则代码，比如工单发起、平台自动化配置等操作。

#### 6.可行性分析

(技术、资源、时间)



#### 7.风险分析

#### 8.资源预算

#### 9.推进计划

#### 10.总结